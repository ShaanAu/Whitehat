{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Time Series: Rolling Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "**After this lesson, you will be able to:**\n",
    "- Define the concepts of trend and seasonality and be able to identify them visually.\n",
    "- Use boxplots to compare distributions.\n",
    "- Plot time series data over time to identify large-scale trends in data.\n",
    "- Investigate trends by computing simple aggregates with Pandas using the `.resample()` function.\n",
    "- Compute rolling statistics with Pandas to compare data of a date to a smaller window of time.\n",
    "- Utilize exponentially weighted windows to average out noise.\n",
    "- Use differences to remove trends in time series data.\n",
    "- Use the Pandas' `.shift()` function to create lagged features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "\n",
    "#### Time Series Rolling Statistics\n",
    "- [Trend and Seasonality](#A)\n",
    "- [Aggregate Data](#B)\n",
    "- [Rolling Statistics](#C)\n",
    "- [Differencing a Time Series and Stationarity](#D)\n",
    "- [Shifting and Lagging Time Series Data](#E)\n",
    "- [Independent Practice](#F)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"A\">Trend and Seasonality</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What constitutes a trend in data? Is linearity required for a trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A trend is any long-term change in the value we're measuring. Trends may “change direction,” going from an increasing trend to a decreasing trend.\n",
    "\n",
    "- Trends can only be measured within the scope of the data collected; there may be trends that are unmeasurable if the data are not complete.\n",
    "\n",
    "An example of an upward trend:\n",
    "![](/assets/images/trend-line2.png)\n",
    "\n",
    "- When patterns repeat over *known, fixed periods* of time within a data set, we call this **seasonality**.\n",
    "\n",
    "- A seasonal pattern exists when a series is influenced by factors related to the cyclic nature of time — i.e., time of month, quarter, year, etc. Seasonality is of a fixed and known period, otherwise it is not truly seasonality. Additionally, it must be either attributed to another factor or counted as a set of anomalous events in the data.\n",
    "\n",
    ">  Can you think of some seasonal patterns from your own experience?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easiest way to visualize trends is by drawing trend lines.\n",
    "#### 1. Import the necessary packages including `timedelta` from d`datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary package including \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Load the `mapquest_google_trends.csv` data in a dataframe\n",
    "* dataset is in the data folder \"data/mapquest_google_trends.csv\"\n",
    "* Rename the columns to 'week_off' and 'hits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data.\n",
    "\n",
    "\n",
    "# Clean/organize the data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Rename the columns as `'week_off'` and `'hits'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns as 'week_off' and 'hits'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot the 'hits' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to compute a coefficient and intercept for our line. NumPy's `polyfit()` method can do this.\n",
    "\n",
    "Then, define our polynomial function using that coefficient. We can do this on a single dimension using NumPy's `poly1d()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# The intercept is ~86.59, the slope is ~0.11.\n",
    "\n",
    "# Let's take a look at the trendline values at specific points:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, plot our trendline over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series using the index as x axis and hits as y axis\n",
    "\n",
    "\n",
    "# Plot the least squares minimizing line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a second-order polynomial might fit our data even better. Let's try that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series.\n",
    "\n",
    "\n",
    "# Plot the least squares minimizing line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** Can you think of any other underlying patterns that might cause trends in time series data? What might cause seasonality in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for trends and seasonality in data made available by a German drugstore, Rossmann.\n",
    "\n",
    "These data contain the daily sales made at the drugstore, as well as whether or not a sale or holiday affected the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are most interested in the `Date` column (which contains the date of sales for each store), we will make sure to process that as a `datetime` type and make it the index of our DataFrame, as we did with our Apple stock data. \n",
    "\n",
    "Let's recall the steps for preprocessing time series data with Pandas:\n",
    "* Convert time data to a `datetime` object.\n",
    "* Set `datetime` to index the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "\n",
    "data = pd.read_csv('data/rossmann.csv', skipinitialspace=True, low_memory=False)\n",
    "\n",
    "# convert the Date column to a date object\n",
    "\n",
    "\n",
    "# set the date as the index\n",
    "\n",
    "# inspect the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to easily filter by date. \n",
    "\n",
    "Let's add a column for `Year` and `Month` based on the `datetime` index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than a million sales data points in this data set, so, for some simple exploratory data analysis (EDA), we'll focus on just one store.\n",
    "\n",
    "*Note: We explicitly add a `.copy()` to the returned DataFrame because we will be making changes to this DataFrame object later. If we didn't specify this, we will receive SettingCopyWarnings later on because Pandas will not know if we want to edit a view of the original data object (`data`) or a separate data object (`store1_data`). Without the `.copy()`, the variable `store1_data` will simply be a reference the original data object in memory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on store 1 and assign to store1_data\n",
    "\n",
    "\n",
    "# inspect the head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate whether or not promotions affect sales. For this, we'll use boxplots.\n",
    "\n",
    "On state holidays, the store is closed (which means there are zero sales), so we need to cut those days out. (Contextual knowledge like this is always necessary to truly explain time series phenomena.)\n",
    "\n",
    "> **Check for Understanding:** Can you think of any other special considerations we should make when tracking sales?\n",
    "\n",
    "Now, check to see if there is a difference affecting sales on promotion days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there _is_ a difference in sales on promotion days.\n",
    "\n",
    "Why is it important to separate out days on which the store is closed? Because there aren't any promotions on those days either, so including them will bias our sales data on days without promotions! Remember to think about the business logic in addition to analyzing the raw data.\n",
    "\n",
    "We may also want to compare sales across days of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to identify larger-scale trends in our data. How did sales change from 2014 to 2015? Were there any particularly interesting outliers in terms of sales or customer visits?\n",
    "\n",
    "To plot the sales and customer visits over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to days Store 1 was open.\n",
    "\n",
    "\n",
    "# plot sales data\n",
    "\n",
    "\n",
    "# plot customer data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are large spikes of sales and customers toward the end of 2013 and 2014, leading into the first quarter of 2014 and 2015.\n",
    "\n",
    "Let's use index filtering to filter just to 2015 changes over time. This should make it easier to identify the holiday sales bump.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to 2015 \n",
    "\n",
    "\n",
    "#plot the sales data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id= \"B\">Aggregate Data</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to investigate trends over time in sales, as always, we'll start by computing simple aggregates. We want to know: What were the mean and median sales in each month and year?\n",
    "\n",
    "We can use `data.resample` on the whole data set and provide:\n",
    "    - A parameter for the level on which to roll up to: `'D'` for day, `'W'` for week, `'M'` for month, `'A'` for year.\n",
    "    - The aggregation method to perform: `mean()`, `median()`, `sum()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean aggregate sales by year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like average sales were highest in 2015. Now, let's look at the median annual sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the sales data by month (using mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of the aggregated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the sales data by month (using median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, see Pandas' `.resample`  [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How do aggregation techniques help us sort out important insights from the noise of time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id = \"C\">Rolling Statistics</a><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With time series, we can \"roll\" statistics across time. For example, the rolling mean is the mean of a moving window across time periods. Pandas offers a variety of functionalities for creating rolling statistics, which we'll only scratch the surface of here.\n",
    "\n",
    "E.g., to understand holidays sales, we don't want to compare sales data in late December with the entire month but instead with a few days immediately surrounding it. We can do this using rolling averages.\n",
    "\n",
    "The syntax for these can be a little tricky at first. We'll be using a `rolling()` function with a statistical function chained to it. Let's dive into more detail.\n",
    "\n",
    "### Parameters for `rolling()` Functions\n",
    "\n",
    "`rolling().mean()` (as well as `rolling().median())` can take the following parameters:\n",
    "\n",
    "* The first indicates the time series to aggregate.\n",
    "* `window` indicates the number of periods to include in the average.\n",
    "* `center` indicates whether the window should be centered on the date or use data prior to that date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the rolling daily sum over all stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.resample()` function to calculate the daily total over all of the stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by day and aggregate sum. assign to variable 'daily_store_sales'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.rolling()` function to calculate the rolling average over a three-day period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our index filtering to just look at 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting the full time series, we can plot the rolling mean instead, which smooths random changes in sales and removes outliers, helping us identify larger trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# compute the rolling statistics over 30 days window and chain to .plot\n",
    "\n",
    "#plot the daily store sales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Expanding Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanding mean simply uses all of the data points up to the current time to calculate the mean, as opposed to a moving window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and plot the expanding mean below. Resample by quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the rolling mean resample by quarter (window=1). assign to 'rolling_mean'\n",
    "\n",
    "# compute the expanding mean and assign to 'expanding_mean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean and expanding mean\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponentially weighted windows are one of the most common and effective ways of averaging out noise in time series data. The averaging is done with an \"exponential decay\" on the contribution of prior means, decreasing the contribution of time points that are further in the past.\n",
    "\n",
    "The (adjusted) exponentially weighted mean for time, $t$, is defined as:\n",
    "\n",
    "<a id=\"-xt--fracxt-----alphaxt------alphaxt--------alphatx------alpha-----alpha-------alphat-\"></a>\n",
    "### $$ x_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2x_{t-1} + ... + (1 - \\alpha)^{t}x_0} {1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^{t}} $$\n",
    "\n",
    "> **Note:** Review Pandas' [documentation](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows) for more information.\n",
    "\n",
    "**Calculate and plot the exponentially weighted sum along with the rolling sum. What's the difference?**\n",
    "\n",
    "For example: `.resample('Q').sum().ewm(span=10).mean()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the data.Sales by Quarter and aggregate on sum, chain to rolling mean over window of 2\n",
    "# assign to the variable 'rolling mean'\n",
    "\n",
    "# resample the data.Sales by Quarter and aggregate on sum, chain to ewm over span of 10\n",
    "# assign to the variable 'exp_weighted_mean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that rolling doesn't understand if you are missing periods (e.g., if you roll over three days and your data are missing weekends, it'll roll Fri/Sat/Sun), so you need to resample first if you care about that.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How does the signal that's captured by rolling statistics differ from the signal captured by resampling time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id = \"D\">Differencing a Time Series and Stationarity</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a time series is stationary, the mean, variance, and autocorrelation (covered in the next section) will be constant over time. Forecasting methods typically assume the time series you are forecasting on to be stationary — or at least approximately stationary.\n",
    "\n",
    "The most common way to make a time series stationary is through \"differencing.\" This procedure converts a time series into the difference between values.\n",
    "\n",
    "<a id=\"-delta-yt--yt---yt--\"></a>\n",
    "### $$ \\Delta y_t = y_t - y_{t-1} $$\n",
    "\n",
    "This removes trends in the time series and ensures that the mean across time is zero. In most cases, this only requires a single difference, although, in some, a second difference (or third, etc.) will be necessary to remove trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check:** How does differencing help with problems of non-stationarity and autocorrelation in time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"E\">Shifting and Lagging Time Series Data</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common operation on time series data is shifting or lagging values backward and forward in time. This can help us calculate the percentage of change from sample to sample. Pandas has a `.shift()` method for shifting the data in a DataFrame.\n",
    "\n",
    "Let's take a look at the Rossman data when we apply lagged features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shift the sales price by one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift store1_data by 1 day\n",
    "\n",
    "\n",
    "# inspect the head\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that the first row now contains NaN values because there wasn't a previous day's data to shift to that day.*\n",
    "\n",
    "Next, let's shift the sales prices by five days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use negative numbers to shift the sales values in the reverse direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lags can be used to calculate the changes in the values you are tracking with your time series data. In this case, we can use Pandas' `.shift()` method to look at the changes in sales. \n",
    "\n",
    "**Let's create a new column in our Rossman DataFrame that contains the previous day's sales.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our new column, it's simple to calculate the one-day change in sales at Store 1. Let's create a new column for this value in our DataFrame as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column sales change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` also has a method called `pct_change` that computes the percentage change of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** What are some other real-world applications you can think of for shifting data in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trends are long-term changes in data. We have to sort through the noise of a time series to identify trends.\n",
    "* We can resample the data to look at simple aggregates and identify patterns.\n",
    "* Rolling statistics give us a local statistic of an average in time, smoothing out random fluctuations and removing outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"F\">Independent Practice</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor Note:** These are optional and can be assigned as student practice questions outside of class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the Unemployment data set. Perform any necessary cleaning and preprocess the data by creating a `datetime` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp = pd.read_csv('./data/unemployment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Plot the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Calculate the rolling mean of years with `window=3 `, without centering, and plot both the unemployment rates and the rolling mean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Calculate the rolling median with `window=5` and `window=15`. Plot both together with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Calculate and plot the expanding mean. Resample by quarter. Plot the rolling mean and the expanding mean together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Calculate and plot the exponentially weighted sum along with the rolling sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Difference the unemployment rate and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
